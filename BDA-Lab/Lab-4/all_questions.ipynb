{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99477117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\r\n"
     ]
    }
   ],
   "source": [
    "! python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bc75671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a428efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SparkOperations').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd028a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "|helpfulness|product_id|        profile_name|              review|score|             summary|      time|       user_id|\n",
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "|        7/7|B003AI2VGA|Brian E. Erland \"...|Synopsis: On the ...|  3.0|\"There Is So Much...|1182729600|A141HP4LYPWMSR|\n",
      "|        4/4|B003AI2VGA|          Grady Harp|THE VIRGIN OF JUA...|  3.0|Worthwhile and Im...|1181952000|A328S9RN3U5M68|\n",
      "|       8/10|B003AI2VGA|Chrissy K. McVay ...|The scenes in thi...|  5.0|This movie needed...|1164844800|A1I7QGUDP043DG|\n",
      "|        1/1|B003AI2VGA|        golgotha.gov|THE VIRGIN OF JUA...|  3.0|distantly based o...|1197158400|A1M5405JH9THP9|\n",
      "|        1/1|B003AI2VGA|KerrLines \"&#34;M...|Informationally, ...|  3.0|\"What's going on ...|1188345600| ATXL536YX71TR|\n",
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('movies.json')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a3cffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[helpfulness: string, product_id: string, profile_name: string, review: string, score: double, summary: string, time: bigint, user_id: string]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ad15073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-------------+--------------------+-----+--------------------+----------+-------+------------------+---------------+\n",
      "|helpfulness|product_id| profile_name|              review|score|             summary|      time|user_id|indexed_product_id|indexed_user_id|\n",
      "+-----------+----------+-------------+--------------------+-----+--------------------+----------+-------+------------------+---------------+\n",
      "|        0/0|         6|      2Foxcee|I was in awe when...|  5.0|  Nostalgic Viewing!|1128988800|  27849|               6.0|        27849.0|\n",
      "|        0/0|         6|A Buckeye Fan|How much did we l...|  5.0|            Memories|1203724800|   8280|               6.0|         8280.0|\n",
      "|        0/0|         6|    A. Bilger|The songs I remem...|  5.0|Beat my high expe...|1263772800|  26952|               6.0|        26952.0|\n",
      "+-----------+----------+-------------+--------------------+-----+--------------------+----------+-------+------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:16 WARN DAGScheduler: Broadcasting large task binary with size 1434.9 KiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "data = spark.read.json('movies.json')\n",
    "\n",
    "# Initialize StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"indexed_product_id\")\n",
    "\n",
    "# Fit and transform the data\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Initialize StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"indexed_user_id\")\n",
    "\n",
    "# Fit and transform the data\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "\n",
    "# Prepare data (convert to appropriate types)\n",
    "# For ALS, you need integer IDs, so ensure that userId and movieId are integers\n",
    "data = data.withColumn(\"user_id\", data[\"indexed_user_id\"].cast(\"integer\"))\n",
    "data = data.withColumn(\"product_id\", data[\"indexed_product_id\"].cast(\"integer\"))\n",
    "data = data.withColumn(\"score\", data[\"score\"].cast(\"float\"))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "training_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baf59904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|user_id|product_id|score|\n",
      "+-------+----------+-----+\n",
      "|     32|       731|  3.0|\n",
      "|      3|       731|  3.0|\n",
      "|    312|       731|  5.0|\n",
      "|  10917|       731|  3.0|\n",
      "|    173|       731|  3.0|\n",
      "|  28065|       731|  2.0|\n",
      "|  34353|       731|  1.0|\n",
      "|  31316|       527|  5.0|\n",
      "|  27884|       527|  5.0|\n",
      "|  19575|       527|  5.0|\n",
      "|  20592|       527|  4.0|\n",
      "|  31841|       527|  5.0|\n",
      "|   9472|       527|  5.0|\n",
      "|  12215|       527|  5.0|\n",
      "|  11514|       527|  4.0|\n",
      "|  27333|       527|  5.0|\n",
      "|  31888|       527|  5.0|\n",
      "|  29767|       527|  5.0|\n",
      "|   5346|       527|  5.0|\n",
      "|   5905|       527|  5.0|\n",
      "|  23015|       374|  5.0|\n",
      "|   1208|       374|  5.0|\n",
      "|  13062|       374|  5.0|\n",
      "|  18159|       374|  5.0|\n",
      "|   8881|       374|  5.0|\n",
      "|  28273|       374|  5.0|\n",
      "|  32273|       374|  5.0|\n",
      "|     36|       374|  3.0|\n",
      "|  10212|       374|  5.0|\n",
      "|   3409|       374|  4.0|\n",
      "|  30271|       374|  5.0|\n",
      "|   7535|       374|  5.0|\n",
      "|  34752|       374|  5.0|\n",
      "|  27172|       374|  5.0|\n",
      "|  17828|       374|  5.0|\n",
      "|  20774|       374|  5.0|\n",
      "|  20576|       374|  5.0|\n",
      "|  30077|       374|  5.0|\n",
      "|  19964|       374|  5.0|\n",
      "|    187|       374|  3.0|\n",
      "|  25786|       374|  4.0|\n",
      "|  16041|       374|  5.0|\n",
      "|   1967|       374|  3.0|\n",
      "|  20913|       374|  1.0|\n",
      "|  11255|       810|  5.0|\n",
      "|  15001|       810|  4.0|\n",
      "|  35462|       810|  4.0|\n",
      "|  19464|       810|  5.0|\n",
      "|  26135|       810|  4.0|\n",
      "|  29280|      1513|  5.0|\n",
      "+-------+----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:16 WARN DAGScheduler: Broadcasting large task binary with size 1417.9 KiB\n"
     ]
    }
   ],
   "source": [
    "data.select('user_id', 'product_id', 'score').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb2ff569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:16 WARN DAGScheduler: Broadcasting large task binary with size 1445.6 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1448.0 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1449.5 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1450.8 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1449.7 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1451.0 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1451.8 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1454.9 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1456.3 KiB\n",
      "24/08/20 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1457.6 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1459.0 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1460.4 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1461.8 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1463.2 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1464.6 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1466.0 KiB\n",
      "24/08/20 15:45:18 WARN DAGScheduler: Broadcasting large task binary with size 1467.4 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1468.7 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1470.1 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1471.5 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1472.9 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1474.3 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1475.7 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1477.1 KiB\n",
      "24/08/20 15:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1478.4 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1479.8 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1481.8 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1480.4 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1433.1 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1489.8 KiB\n",
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1488.4 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test-data:\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "| 0.7946394|\n",
      "| 2.1851506|\n",
      "|  2.264963|\n",
      "|0.18443355|\n",
      "|0.37264916|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1433.1 KiB\n",
      "24/08/20 15:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1489.8 KiB\n",
      "24/08/20 15:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1488.4 KiB\n",
      "24/08/20 15:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1535.1 KiB\n",
      "24/08/20 15:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1536.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 3.705745542003063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1530.5 KiB\n",
      "24/08/20 15:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1536.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     31|[{295, 24.73688},...|\n",
      "|     53|[{280, 34.535423}...|\n",
      "|     65|[{524, 30.038858}...|\n",
      "|     85|[{717, 29.74633},...|\n",
      "|    133|[{609, 26.783337}...|\n",
      "|    137|[{497, 18.771286}...|\n",
      "|    148|[{409, 38.030365}...|\n",
      "|    243|[{557, 21.46371},...|\n",
      "|    251|[{524, 21.065498}...|\n",
      "|    255|[{609, 40.45455},...|\n",
      "|    296|[{485, 32.664505}...|\n",
      "|    392|[{487, 21.62275},...|\n",
      "|    451|[{484, 18.76271},...|\n",
      "|    458|[{777, 12.584575}...|\n",
      "|    463|[{540, 18.650095}...|\n",
      "|    471|[{482, 20.19489},...|\n",
      "|    472|[{540, 20.023144}...|\n",
      "|    481|[{661, 22.829561}...|\n",
      "|    496|[{280, 18.78143},...|\n",
      "|    516|[{924, 20.769314}...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 203:===========================>                         (51 + 24) / 100]\r",
      "\r",
      "[Stage 203:=================================>                   (63 + 24) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|     recommendations|\n",
      "+----------+--------------------+\n",
      "|         1|[{114, 7.04719}, ...|\n",
      "|         3|[{164, 8.059383},...|\n",
      "|         6|[{53, 7.3535886},...|\n",
      "|        12|[{274, 9.24094}, ...|\n",
      "|        13|[{152, 7.7875967}...|\n",
      "|        16|[{142, 9.762384},...|\n",
      "|        20|[{255, 8.019079},...|\n",
      "|        22|[{276, 8.496781},...|\n",
      "|        26|[{244, 14.589832}...|\n",
      "|        27|[{158, 8.411977},...|\n",
      "|        28|[{291, 9.180564},...|\n",
      "|        31|[{255, 10.677561}...|\n",
      "|        34|[{255, 11.425577}...|\n",
      "|        40|[{123, 14.355308}...|\n",
      "|        44|[{357, 12.652631}...|\n",
      "|        47|[{53, 17.900494},...|\n",
      "|        52|[{276, 12.373009}...|\n",
      "|        53|[{189, 12.72678},...|\n",
      "|        54|[{214, 15.111511}...|\n",
      "|        57|[{244, 18.820381}...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 15:45:24 WARN DAGScheduler: Broadcasting large task binary with size 1530.0 KiB\n",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize ALS model\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.01,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"product_id\",\n",
    "    ratingCol=\"score\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "print(\"Predictions on test-data:\")\n",
    "predictions.select('prediction').show(5)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"score\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "user_recs = model.recommendForAllUsers(10)\n",
    "user_recs.show()\n",
    "\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movie_recs = model.recommendForAllItems(10)\n",
    "movie_recs.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
